自适应实例归一化（Adaptive Instance Normalization，AdaIN）是一种用于风格迁移和图像生成的归一化方法，由Huang & Belongie在2017年提出。以下是详细介绍：
- **核心思想**：AdaIN的核心思想是让目标风格图像的统计信息（均值和标准差）直接影响内容图像的特征，从而实现风格转换。均值表示图像的整体色调，标准差反映图像的对比度或纹理分布，通过调整内容特征的均值和标准差，使其匹配风格图像的统计信息，就能在保留内容的同时注入风格信息。
- **计算公式**：给定一个内容特征图$x$和一个风格特征图$y$，AdaIN的计算公式为$$\text{AdaIN}(x,y)=\sigma(y)\frac{x - \mu(x)}{\sigma(x)}+\mu(y)$$
其中$\mu(x), \sigma(x)$分别是内容特征的均值和标准差，$\mu(y), \sigma(y)$分别是风格特征的均值和标准差。首先对内容特征$x$进行实例归一化，使其变成标准正态分布，然后用风格特征$y$的均值和标准差重新调整内容特征，使其统计信息匹配风格图像。
- **与其他归一化方法的区别**：Batch Normalization（BN）是在整个批次上进行归一化，Batch维度共享归一化参数；Instance Normalization（IN）是在逐个样本内进行归一化，计算单个样本每个通道的均值和标准差；而AdaIN则是用风格特征的均值和标准差替换内容特征的均值和标准差，主要用于风格迁移和GAN等任务，实现风格和内容的融合。
- **在风格迁移中的应用**：AdaIN最初用于风格迁移任务，相比传统的基于VGG - 19的风格损失方法，AdaIN直接利用风格图像的均值和标准差来调整内容图像的特征，简化了计算过程，不需要复杂的风格损失，只需通过前馈网络即可实现风格化。具体流程为提取内容图像和风格图像的特征，使用AdaIN归一化内容图像使其风格化，最后经过解码器将特征重建回图像。这种方法运行速度快，效果也更自然。
- **在StyleGAN中的应用**：AdaIN是StyleGAN生成对抗网络的核心组件之一。在StyleGAN中，生成器采用映射网络将输入噪声$z$映射到一个潜在空间$w$，这个$w$向量被用于调整AdaIN层的均值和标准差，实现可控的风格变化。StyleGAN通过AdaIN控制不同尺度的风格特征，低层决定整体面部结构，高层控制细节，如皮肤纹理、发型等。同时，利用AdaIN可实现风格平滑插值，通过多层AdaIN分层控制不同尺度的风格，能生成多样化的图像。
- **优势**：与传统的风格迁移方法相比，AdaIN不仅能够实现更灵活的风格融合，还能在保持图像内容的同时，赋予其独特的艺术风格，使得实时任意风格迁移变得更加可行和高效。