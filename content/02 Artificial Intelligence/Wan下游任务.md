---
title: "Wan下游任务"
date: 2025-10-29
draft: false
---

下游任务扩展架构
Wan基于基础模型扩展了8类下游任务，通过**统一条件注入**、**适配器（Adapter）** 等设计，实现多任务复用与高效适配。

### 4.1 图像到视频（I2V）生成
- **核心设计**：将输入图像作为第一帧，与零填充帧拼接后经Wan-VAE压缩为条件latent；引入二进制掩码标记“保留帧”与“生成帧”，通过跨注意力注入CLIP图像特征作为全局上下文；
- **多任务统一**：支持图像转视频、视频续帧、首尾帧过渡等任务，通过“联合预训练+任务微调”实现，预训练阶段复用T2V数据集，微调阶段使用任务专属数据集（如高相似度首帧视频集）。

### 4.2 统一视频编辑（VACE框架）
- **视频条件单元（VCU）**：将文本指令、参考帧、掩码统一为 \([T; F; M]\) 输入格式（T为文本，F为帧序列，M为二进制掩码）；
- **概念解耦（Concept Decoupling）**：通过掩码将帧分为“待修改帧（F_c）”和“保留帧（F_k）”，分别编码为latent，确保编辑目标明确；
- **训练模式**：支持“全模型微调”和“上下文适配器微调”（Res-Tuning范式），后者无需修改基础模型权重，仅通过适配器注入编辑条件。

### 4.3 视频个性化生成
- **身份注入**：无需依赖ArcFace等特征提取器，直接将用户提供的人脸图像在Wan-VAE latent空间中扩展为K帧，与全1掩码拼接作为条件；
- **扩散过程**：在latent空间中对“扩展人脸帧+生成视频帧”联合去噪，训练时随机丢弃部分人脸帧，支持0-K个参考人脸的灵活生成；
- **数据集构建**：从T2V数据中筛选单一人脸视频，结合Instant-ID合成多样化人脸数据，提升风格与姿态泛化性。

### 4.4 其他扩展任务
- **相机运动控制**：通过Plücker坐标将相机内外参转换为像素级位置特征，经卷积编码器提取运动特征，再通过自适应归一化注入DiT模块，实现平移、缩放、追踪等相机运动控制；
- **实时视频生成**：基于Streamer框架，通过滑动时间窗口处理长序列，结合Latent Consistency Model（LCM）蒸馏，将采样步骤从50步降至4步，实现8-20 FPS的实时生成；
- **视频到音频（V2A）生成**：采用1D-VAE处理音频波形，通过CLIP提取视频帧特征并与音频特征对齐，结合umT5文本编码，生成与视频同步的环境音和背景音乐。

