---
title: "self-forcing"
date: 2025-08-07
draft: false
---

### 研究问题
本文针对自回归视频扩散模型（autoregressive video diffusion models）中存在的**训练-测试分布不匹配问题**（exposure bias）展开研究。具体表现为：
1. **传统方法局限性**：现有方法（如Teacher Forcing和Diffusion Forcing）在训练时依赖真实帧或噪声帧作为上下文，但推理时需基于模型自身生成的误差累积帧，导致生成质量随时间退化。
2. **实时性需求**：双向注意力扩散模型无法满足实时流式生成（如交互式应用）的低延迟要求，而现有自回归模型因依赖有损向量量化技术难以达到高质量生成。

### 研究方法
1. **Self Forcing训练范式**：
   - **自回归展开训练**：在训练阶段模拟推理过程，通过KV缓存机制逐帧生成，使模型基于自身历史输出生成后续帧（如图1c所示）。
   
   - **梯度截断策略**：仅对每帧的最后去噪步骤计算梯度，结合随机步长采样（Algorithm 1），平衡计算效率与训练效果。

2. **整体分布匹配损失**：
   - 采用视频级损失（DMD/SiD/GAN）直接优化生成序列与真实数据的分布对齐，而非传统逐帧损失。例如DMD损失通过KL散度最小化实现（公式3）。

3. **滚动KV缓存机制**（Algorithm 2）：
   - 固定大小缓存窗口动态更新，实现长视频生成的O(TL)复杂度（图3c），避免传统滑动窗口的重复计算问题。
   

### 主要结论
1. **性能优势**：
   - 在单H100 GPU上实现17 FPS实时生成（延迟<0.69秒），VBench总分84.31超越基线（表1），用户偏好率显著领先（图4）。
   - 长视频生成中，滚动KV缓存将吞吐量从4.6 FPS提升至16.1 FPS（附录B）。

2. **质量突破**：
   - 自回归生成质量媲美非因果扩散模型（如Wan2.1），且避免CausVid的饱和度累积问题（图5）。
   

3. **训练效率**：
   - 尽管采用序列化训练，因并行化token处理与优化注意力内核（FlashAttention-3），实际训练时间与TF/DF相当（图6），1.5小时即可收敛。

### 创新点
1. **训练-测试对齐**：
   - 首次在视频扩散模型中实现训练阶段的自回归展开，从根本上解决exposure bias问题（图1c）。

2. **混合架构设计**：
   - 融合自回归的链式分解、扩散模型的连续值生成、以及GAN的分布匹配思想，形成统一框架。

3. **工程优化突破**：
   - 提出梯度截断策略使自回归训练可行，滚动KV缓存机制实现首个高效无限长视频生成方案。

4. **范式革新**：
   - 提出"并行预训练+序列后训练"新范式，为序列生成任务提供通用解决方案（第5章讨论）。