---
aliases:
  - 聚类指标
tags:
  - "#轮廓系数"
  - "#Calinski-Harabasz指数"
---
在您的代码中，**轮廓系数**和**Calinski-Harabasz指数**都是用来评估聚类效果好坏的指标，它们能帮助判断数据点聚类是否“内紧外松”。下表清晰地展示了它们的核心特点与差异：

| 评估指标                    | 核心思想                            | 计算公式                                     | 数值范围    | 最佳值    | 主要特点              |
| :---------------------- | :------------------------------ | :--------------------------------------- | :------ | :----- | :---------------- |
| **轮廓系数**                | 综合考察样本与自身簇的紧密度（a）和与最近其他簇的分离度（b） | `s(i) = (b(i) - a(i)) / max(a(i), b(i))` | [-1, 1] | 越接近1越好 | 结果直观，能反映单个样本的聚类情况 |
| **Calinski-Harabasz指数** | 衡量簇间离散度（分离度）与簇内离散度（紧密度）的比率      | `CH = [B(k)/(k-1)] / [W(k)/(n-k)]`       | [0, +∞) | 越大越好   | 计算效率通常高于轮廓系数      |

### 💡 指标解读与代码分析
```python
from sklearn.metrics import silhouette_score, calinski_harabasz_score

def evaluate_clustering(self):
	"""
	评估聚类质量
	"""
	if self.labels_ is None:
		raise ValueError("No clustering results. Call cluster() first.")
	
	# 只评估有效聚类（排除噪声点）
	valid_mask = self.labels_ >= 0
	valid_features = self.features_[valid_mask]
	valid_labels = self.labels_[valid_mask]
	
	if len(np.unique(valid_labels)) < 2:
		print("Not enough clusters for evaluation")
		return {}
	
	scores = {}
	
	# 轮廓系数
	if len(valid_labels) > 1:
		try:
			silhouette_avg = silhouette_score(valid_features, valid_labels)
			scores['silhouette_score'] = silhouette_avg
		except:
			scores['silhouette_score'] = -1
	
	# Calinski-Harabasz指数
	try:
		ch_score = calinski_harabasz_score(valid_features, valid_labels)
		scores['calinski_harabasz_score'] = ch_score
	except:
		scores['calinski_harabasz_score'] = -1
	
	print("Clustering evaluation scores:")
	for metric, score in scores.items():
		print(f"  {metric}: {score:.4f}")
	
	return scores
```
理解表格中的基本概念后，我们来进一步解读这些指标的具体含义，并分析您代码中的一些细节：

*   **解读轮廓系数**：对于一个样本点，其轮廓系数 `s(i)` 的含义可以根据其值进行判断：
    *   **接近1**：说明 `b(i)` 远大于 `a(i)`。这意味着该点距离自己所属的簇很近，而离其他簇很远，聚类结果合理。
    *   **接近0**：说明 `a(i)` 和 `b(i)` 差不多。该点可能处于两个簇的边界，归属不明确。
    *   **小于0**：说明 `a(i)` 大于 `b(i)`。这意味着该点离其他簇的点更近，很可能被分配到了错误的簇中。

*   **解读Calinski-Harabasz指数**：该指数越高，通常意味着簇间差异大、簇内差异小，即聚类效果越好。

*   **代码设计分析**：您的代码实现中有几个细节处理得很好：
    *   **有效性检查**：在计算轮廓系数前，代码通过 `if len(valid_labels) > 1` 进行检查。这是因为至少需要两个不同的簇，计算轮廓系数才有意义。
    *   **异常处理**：使用 `try-except` 块包裹计算过程是个好习惯。一旦计算过程出错（例如，由于数据问题或聚类结果不理想），会将得分设为 `-1`，避免程序意外终止，保证了代码的鲁棒性。

### 🎯 如何应用这些指标

在实际的聚类分析项目中（比如您代码中涉及的图像聚类），您可以这样运用这些指标：

*   **横向比较**：用相同的评估指标（如固定使用轮廓系数）去比较**不同聚类算法**（如K-Means、DBSCAN、层次聚类）在同一数据集上的表现，从而选择最适合当前数据的算法。

*   **参数调优**：用这些指标来帮助确定**最佳聚类数量**。例如，在K-Means算法中，您可以尝试不同的k值（如从2到10），分别计算每个k值对应的轮廓系数或CH指数。通常，得分最高的k值被认为是较优的选择。

希望这些详细的解释能帮助您更好地理解和使用这些聚类评估指标。如果您对特定聚类算法（如K-Means或DBSCAN）如何选择参数有更具体的问题，我很乐意提供进一步的分析。