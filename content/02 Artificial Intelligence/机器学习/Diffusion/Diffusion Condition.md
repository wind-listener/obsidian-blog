扩散模型通过**条件嵌入机制**将外部信息（如文本、图像、类别标签）融入去噪过程，主要接入方式分为以下四类：

### 一、条件类型与核心机制
#### 1. 文本条件
- **CLIP语义对齐**：文本通过CLIP编码器生成语义向量，作为交叉注意力的Key/Value，与图像特征（Query）交互。
- **交叉注意力注入**：在U-Net或Transformer的瓶颈层，文本向量通过交叉注意力引导去噪方向，如Stable Diffusion中每一层均嵌入文本条件。

#### 2. 图像条件
- **空间对齐控制**：边缘图、深度图等通过编码器转换为特征图，与U-Net的中间特征拼接或通过注意力融合，如ControlNet和OminiControl。
- **主体特征保持**：通过多模态注意力机制，将条件图像的主体特征与生成过程中的隐变量对齐，实现风格迁移或内容约束。

#### 3. 类别条件
- **标签嵌入**：类别标签通过MLP转换为向量，与时间步嵌入相加后注入模型，如DiT中的In-context conditioning。
- **Classifier-Free Guidance**：训练时随机丢弃条件标签，推理时通过条件与无条件预测的差值增强类别约束，避免依赖外部分类器。

### 二、模型接入方式
#### 1. 交叉注意力机制
- **全局上下文建模**：Transformer架构（如DiT）中，文本或图像条件作为独立token序列，通过多头交叉注意力与图像token交互，捕捉全局语义关联。
- **层级融合**：在U-Net的不同分辨率层级插入交叉注意力模块，实现多尺度条件引导，如Stable Diffusion的文本-图像对齐。

#### 2. 归一化参数动态调整
- **adaLN（Adaptive Layer Normalization）**：将条件向量通过MLP映射为归一化层的γ和β参数，动态调整特征分布，如DiT的条件注入。
- **残差连接增强**：adaLN-Zero进一步将条件信号融入残差路径，强化条件对特征更新的影响。

#### 3. 时间步与条件联合嵌入
- **正弦位置编码**：时间步t通过正弦函数编码为向量，与条件向量（如文本、类别）拼接后输入模型，实现时间-条件联合引导。
- **隐空间条件投影**：在潜空间扩散模型（如Stable Diffusion）中，条件信息通过VAE压缩后与潜变量结合，降低计算复杂度。

#### 4. 采样阶段条件优化
- **动态引导尺度**：通过调节Classifier-Free Guidance的CFG Scale，控制条件约束强度，平衡生成多样性与语义一致性。
- **交叉注意力缓存**：推理早期交叉注意力输出趋于稳定，可缓存以减少后续步骤计算量，如TGate方法加速文本条件生成。

### 三、典型模型实现案例
#### 1. Stable Diffusion
- **文本条件**：CLIP文本编码器生成768维语义向量，通过交叉注意力注入U-Net的每个ResNet块和注意力层，实现文本到图像的精确对齐。
- **多模态扩展**：通过ControlNet接入边缘图、深度图等空间条件，增强对生成结构的控制。

#### 2. DiT（Diffusion Transformer）
- **纯Transformer架构**：图像分块为token序列，文本条件作为独立token，通过交叉注意力实现全局语义融合。
- **条件嵌入策略**：支持In-context conditioning（拼接条件token）、adaLN（动态归一化）等多种方式，灵活性高。

#### 3. OminiControl
- **通用条件框架**：复用DiT组件，通过显式位置嵌入和多模态注意力，同时支持边缘、深度、主体等多类型条件，参数开销仅0.1%。

### 四、核心优势与未来趋势
- **灵活性**：可无缝接入文本、图像、3D几何等多模态条件，适应多样化生成需求。
- **可控性**：通过交叉注意力和动态归一化，实现细粒度语义与空间控制。
- **效率优化**：如TGate的交叉注意力缓存、OminiControl的轻量级设计，提升条件生成的实时性。

未来方向包括**连续时间条件建模**（将条件作为SDE的驱动项）和**跨模态动态对齐**（如视频生成中的时空条件融合），进一步提升条件生成的泛化能力与应用场景。