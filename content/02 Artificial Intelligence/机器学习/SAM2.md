---
title: "SAM2"
date: 2025-08-07
draft: false
---


![[Pasted image 20250213134426 1.png]]
文件主要介绍了 **Segment Anything Model 2 (SAM 2)**，一种面向图像和视频的可提示分割基础模型的改进版本。以下是摘要和关键内容：
![[SAM2 overview.png]]
  
**核心创新**

1. **统一模型设计**：SAM 2 扩展了原始 SAM 的图像分割能力，将其应用到视频中，采用了基于记忆的流式架构，能够在视频帧之间保留目标信息。

2. **Promptable Visual Segmentation (PVS)**：提出了通用的可提示视觉分割任务，支持点、框或掩码提示在视频任意帧中定义目标，并通过交互方式优化分割结果。

3. **高效数据引擎**：通过人机交互收集了史上最大的 SA-V 视频分割数据集，包含 50,900 个视频和 35.5M 掩码，支持对任意对象进行高质量分割。


# **模型架构**
![[Pasted image 20250213134426 1.png]]
• 基于 Transformer 的内存模块：

• **记忆模块**：存储目标对象的上下文信息，利用之前帧的记忆优化分割结果。

• **轻量化掩码解码器**：通过提示生成单帧或多帧的目标掩码。

• **多模态训练**：结合静态图像和视频数据进行联合训练。

• **流式处理**：逐帧处理视频，实现实时分割。

  

**数据集和性能**

1. **SA-V 数据集**：

• 包括手动和自动生成的掩码，掩码数量为现有数据集的 53 倍。

• 涵盖多种场景和物体类型，注重地理多样性和公平性评估。

2. **性能对比**：

• 在视频和图像任务上均超过现有模型，且交互次数减少了 3 倍，分割速度提高了 6 倍。

  

**应用领域**

  

SAM 2 能力在以下领域具有潜在应用：

• AR/VR、自动驾驶、机器人视觉等需要时序分割的场景。

• 视频编辑和医疗影像等需要精确分割的应用。

  

如果有特定问题或需要详细解释某部分内容，请告知！