---
title: "机器学习常用指标"
date: 2025-08-07
draft: false
---

这些参数都是用于评估分类模型性能的常见指标，它们来源于**混淆矩阵**（Confusion Matrix）。详细介绍如下：

  

**1. 混淆矩阵（Confusion Matrix）**

  

对于二分类任务（例如缺陷检测：有缺陷 vs 无缺陷），混淆矩阵如下：

||**预测正类 (Positive)**|**预测负类 (Negative)**|
|---|---|---|
|**实际正类 (True)**|TP (True Positive)|FN (False Negative)|
|**实际负类 (False)**|FP (False Positive)|TN (True Negative)|

**各个指标的定义：**

• **TP（True Positive）：真正例**

• 预测为正类，实际也是正类（例如：模型正确检测到有缺陷）。

• **FP（False Positive）：假正例（误报）**

• 预测为正类，实际是负类（例如：模型错误地将无缺陷的样本判断为有缺陷）。

• **FN（False Negative）：假负例（漏报）**

• 预测为负类，实际是正类（例如：模型错误地将有缺陷的样本判断为无缺陷）。

• **TN（True Negative）：真负例**

• 预测为负类，实际也是负类（例如：模型正确地检测到无缺陷）。

  

**2. 评估指标计算**

  

假设 all_labels 是实际标签，all_preds 是模型预测的标签。

  

**(1) Precision（精确率）**

  

$$

\text{Precision} = \frac{TP}{TP + FP}

$$

• **含义**：在所有被预测为正类的样本中，真正例的比例。

• **用途**：高精确率表示误报（FP）少，例如在医疗检测中，减少误诊的重要性较高时优先考虑。

  

**(2) Recall（召回率）**

  

$$

\text{Recall} = \frac{TP}{TP + FN}

$$

• **含义**：在所有实际正类样本中，被正确预测为正类的比例。

• **用途**：高召回率表示漏报（FN）少，例如在安全检测中，减少漏检至关重要。

  

**(3) F1 Score（F1 值）**

  

$$

\text{F1 Score} = \frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}

$$

• **含义**：精确率和召回率的调和平均值，综合考虑二者的权衡。

• **用途**：当 FP 和 FN 都需要被关注时，F1-score 是一个很好的综合指标。

  

**(4) Accuracy（准确率）**

  

$$

\text{Accuracy} = \frac{TP + TN}{TP + FP + FN + TN}

$$

• **含义**：所有预测正确的样本占总样本的比例。

• **计算方式**： correct / total，其中 correct 是正确分类的样本数，total 是总样本数。

• **局限性**：

• 在 **类别不均衡（imbalanced dataset）** 时，准确率可能会误导。例如，在缺陷检测任务中，99% 的产品无缺陷，模型即使全部预测为“无缺陷”，也能达到 99% 的准确率，但实际上模型没有学到有效的模式。

  

**3. Python 代码示例**

```python
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score

def calculate_metrics(y_true, y_pred):
    """
    计算分类模型的评估指标
    :param y_true: 真实标签
    :param y_pred: 预测标签
    :return: precision, recall, f1_score, accuracy
    """
    tn = sum((y_true == 0) & (y_pred == 0))
    tp = sum((y_true == 1) & (y_pred == 1))
    fn = sum((y_true == 1) & (y_pred == 0))
    fp = sum((y_true == 0) & (y_pred == 1))

    precision = precision_score(y_true, y_pred, zero_division=0)
    recall = recall_score(y_true, y_pred, zero_division=0)
    f1 = f1_score(y_true, y_pred, zero_division=0)
    accuracy = accuracy_score(y_true, y_pred)

    return tn, fp, fn, tp, precision, recall, f1, accuracy

# 示例数据
import numpy as np
y_true = np.array([1, 0, 1, 1, 0, 1, 0, 0, 1, 0])
y_pred = np.array([1, 0, 1, 0, 0, 1, 1, 0, 1, 0])

tn, fp, fn, tp, precision, recall, f1, accuracy = calculate_metrics(y_true, y_pred)
print(f"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}")
print(f"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}, Accuracy: {accuracy:.4f}")
```

**4. 何时使用 Precision、Recall、F1 Score？**

• **高精确率（Precision）优先**：当误报的代价较高时，例如：

• **医疗检测**（避免误诊导致过度治疗）。

• **垃圾邮件过滤**（避免误拦正常邮件）。

• **高召回率（Recall）优先**：当漏报的代价较高时，例如：

• **安全检测**（防止危险情况被忽略）。

• **缺陷检测**（确保所有缺陷产品被筛选出）。

• **F1 Score**：当误报和漏报都很重要时（例如 NLP 任务、信息检索等）。

  

**5. 总结**

|**指标**|**计算公式**|**适用场景**|
|---|---|---|
|**Precision（精确率）**|$\frac{TP}{TP+FP}$|误报（FP）代价高的任务（如医疗、垃圾邮件过滤）|
|**Recall（召回率）**|$\frac{TP}{TP+FN}$|漏报（FN）代价高的任务（如安全检测、缺陷检测）|
|**F1 Score**|$\frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$|平衡 Precision 和 Recall|
|**Accuracy（准确率）**|$\frac{TP + TN}{TP + FP + FN + TN}$|适用于类别平衡的任务，不适用于类别不均衡的情况|

如果你的数据类别严重不均衡（例如缺陷检测中 99% 的产品无缺陷），F1-score 或 AUC-ROC 可能是比 Accuracy 更好的衡量标准。


**机器学习常用评估指标总结（按任务类型）**

  

在机器学习任务中，评估指标用于衡量模型的性能，确保模型在实际应用中能产生有效的预测结果。不同任务类型使用不同的指标，下面按**分类任务、回归任务、排序任务、聚类任务、生成任务**进行总结。

---

**1. 分类任务（Classification）**

  

分类任务涉及将数据点分配到有限的类别中，如**二分类**（有缺陷/无缺陷）和**多分类**（猫/狗/鸟）。

| **指标**                             | **公式**                                                                                    | **说明**                | **适用场景**                |
| ---------------------------------- | ----------------------------------------------------------------------------------------- | --------------------- | ----------------------- |
| **准确率 (Accuracy)**                 | $\frac{TP + TN}{TP + TN + FP + FN}$                                                       | 预测正确的样本占总样本的比例        | 适用于类别均衡的数据集，不适用于类别不均衡问题 |
| **精确率 (Precision)**                | $\frac{TP}{TP + FP}$                                                                      | 预测为正类的样本中，实际为正类的比例    | 误报代价高的场景，如医疗诊断          |
| **召回率 (Recall)**                   | $\frac{TP}{TP + FN}$                                                                      | 真实正类中被正确预测的比例         | 漏报代价高的场景，如异常检测          |
| **F1 值 (F1 Score)**                | $\frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$ | 精确率和召回率的调和平均          | 需要权衡误报和漏报的场景            |
| **ROC 曲线 (ROC Curve)**             | -                                                                                         | 反映不同阈值下的分类能力          | 适用于类别不均衡问题              |
| **AUC（ROC 下的面积）**                  | -                                                                                         | 0.5-1 之间，越接近 1 代表模型越好 | 适用于类别不均衡问题              |
| **PR 曲线 (Precision-Recall Curve)** | -                                                                                         | 适用于类别不均衡问题            | 关注正类样本的分类性能             |

🔹 **特殊场景**：

• **类别不均衡**（如诈骗检测）：使用 **AUC-ROC, AUC-PR, F1 Score**

• **多分类问题**：使用 **Macro-F1（平均权重）、Weighted-F1（按样本数加权）**

---

**2. 回归任务（Regression）**

  

回归任务用于预测连续值，例如预测房价、温度、销售额等。

| **指标**                              | **公式**                                                  | **说明**                                   | **适用场景**          |
| ----------------------------------- | ------------------------------------------------------- | ---------------------------------------- | ----------------- |
| **均方误差 (MSE)**                      | $\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$        | 对大误差敏感                                   | 适用于对大误差敏感的场景      |
| **均方根误差 (RMSE)**                    | $\sqrt{MSE}$                                            | 误差的平方根                                   | 解释性更强，单位与原数据一致    |
| **平均绝对误差 (MAE)**                    | $\frac{1}{n} \sum_{i=1}^{n}y_i - \hat{y}_i$             |                                          |                   |
| **R² 决定系数**                         | $1 - \frac{\sum (y - \hat{y})^2}{\sum (y - \bar{y})^2}$ | 反映模型对数据的解释能力，取值范围 $(-\infty,1]$，越接近 1 越好 | 适用于评估回归模型的整体拟合度   |
| **解释方差 (Explained Variance Score)** | $1 - \frac{\text{Var}(y - \hat{y})}{\text{Var}(y)}$     | 衡量预测值的变化程度                               | 适用于衡量预测波动是否符合数据波动 |

🔹 **选择指南**：

• **对异常值敏感的任务**（如金融数据）：**MSE**

• **对异常值不敏感**（如温度预测）：**MAE**

• **整体模型好坏评估**：**R²**

---

**3. 排序任务（Ranking）**

  

排序任务常见于搜索引擎、推荐系统，例如电商推荐商品排序。

| **指标**                                                      | **公式**                            | **说明**              | **适用场景**   |
| ----------------------------------------------------------- | --------------------------------- | ------------------- | ---------- |
| **平均精度均值 (MAP, Mean Average Precision)**                    | $\frac{1}{Q} \sum_{q=1}^{Q} AP_q$ | 计算多个查询的平均精度         | 信息检索       |
| **归一化折损累计增益 (NDCG, Normalized Discounted Cumulative Gain)** | $\frac{DCG}{IDCG}$                | 考虑结果的排名和相关性         | 排名任务，如搜索引擎 |
| **Top-K 精度 (Precision@K, Recall@K)**                        | -                                 | 计算前 K 个推荐结果的精确率/召回率 | 推荐系统       |

🔹 **选择指南**：

• **搜索引擎优化**：使用 **MAP, NDCG**

• **推荐系统优化**：使用 **Precision@K, Recall@K**

---

**4. 聚类任务（Clustering）**

  

无监督学习中的聚类任务评估模型的聚类效果，例如 K-Means, DBSCAN。

| **指标**                                       | **公式**                     | **说明**              | **适用场景** |
| -------------------------------------------- | -------------------------- | ------------------- | -------- |
| **轮廓系数 (Silhouette Score)**                  | $\frac{b - a}{\max(a, b)}$ | 衡量聚类质量，范围 $[-1, 1]$ | 评估聚类分布   |
| **调整兰德指数 (ARI, Adjusted Rand Index)**        | -                          | 真实标签与聚类结果的相似度       | 监督聚类     |
| **互信息 (NMI, Normalized Mutual Information)** | -                          | 真实类别和聚类结果的信息相似性     | 评估聚类算法   |

🔹 **选择指南**：

• **无监督任务**：使用 **Silhouette Score**

• **有监督聚类**：使用 **ARI, NMI**

---

**5. 生成任务（Generative Tasks）**

  

包括图像生成（GAN）、文本生成（LLM）、风格转换等。

|**指标**|**公式**|**说明**|**适用场景**|
|---|---|---|---|
|**FID（Fréchet Inception Distance）**|计算真实图像与生成图像的分布差异|评估生成图像的质量|图像生成|
|**IS（Inception Score）**|衡量生成图像的多样性和可识别性|适用于生成对抗网络（GANs）|图像生成|
|**BLEU（Bilingual Evaluation Understudy）**|计算预测文本和目标文本的 n-gram 重叠|机器翻译||
|**ROUGE（Recall-Oriented Understudy for Gisting Evaluation）**|计算召回率，评估文本生成|摘要生成||
|**Perplexity（困惑度）**|计算文本生成模型对数据的拟合程度|NLP 生成任务||

🔹 **选择指南**：

• **图像生成任务**（如 GAN）：**FID, IS**

• **NLP 文本生成**（如翻译、摘要）：**BLEU, ROUGE, Perplexity**

---

**总结**

  

不同任务使用不同评估指标：

1. **分类**：准确率、精确率、召回率、F1、AUC-ROC

2. **回归**：MSE、MAE、R²

3. **排序**：MAP、NDCG、Precision@K

4. **聚类**：Silhouette Score、ARI、NMI

5. **生成**：FID、BLEU、ROUGE

  

选择合适的评估指标，能更科学地衡量模型的性能！🚀